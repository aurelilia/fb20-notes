# 9. Message Passing Interface
*Notes on the various methods for passing data not complete.*
*Reference the slides for more detail.*

Message passing for distributed memory, with private address space for
each process. Explicit communication

### Advantages
- Universality: Works on distributed and shared memory architectures
- Expressitivity: Intuitive model for parallelism
- Easy to debug: Easier than shared memory models
- Performance/scalability: Data locality is explicit, scales well

### Disadvantages
- Incremental application hard; redesign often needed
- Low-level primitives: Pulls attention away from original problem
- Communication overhead: Can be bottleneck at large scale
- MPI is complex


## MPI
Standard similar to OpenMP, pure library, no compiler machinery.
Version 1.0 from 1994; bindings for Fortran and C(++)

Feature creep makes it big; Version 4.0 from 2021 has 1100 pages of spec.  
Main use through `mpi.h`

### Message buffers
Tuple of `(address, count, datatype)`; i.e. `(arr, 300, MPI_REAL)`

### Communicators
Messages are sent in a message context allocated at runtime; most of the
time a communicator combining context and thread group is used.  
`MPI_COMM_{WORLD,SELF}` are predefined communicators.

### Functions
- `MPI_Init(argc, argv)`: Initialize the runtime
- `MPI_Comm_size(comm, *size)`: Get total number of processes in comm
- `MPI_Comm_rank(comm, *rank)`: Get own identifier (rank) in given comm
- `MPI_Send(addr, cnt, type, dest, tag, comm)`: Blocking send
- `MPI_Recv(addr, max_cnt, type, src, tag, comm, status)`: Blocking receive
- `MPI_Sendrecv(saddr, ..., rbuf, ..., comm, status)`: Simultaneous send/recv
  to avoid deadlocks 
- `MPI_Bcast(buf, cnt, type, root, comm)`: Broadcast from root rank to all 
  other processes in comm
- `MPI_Reduce(*send, *recv, cnt, type, op, root, comm)`: Combines elements in
  `send` of each process using `op` and returns combined value in `recv`
  of the `root` rank process
- `MPI_Allreduce(*send, *recv, cnt, type, op, comm)`: Combines elements in
  `send` of each process using `op` and returns combined value in `recv`
  of all processes
- `MPI_Finalize()`: Terminate runtime

### Predefined things
Datatypes starting with `MPI_`: `CHAR SHORT INT LONG`
(and `UNSIGNED` variants),
`FLOAT DOUBLE LONG_DOUBLE BYTE PACKED LONG_LONG_INT`

Reduction ops: `MAX MIN SUM PROD LAND BAND LOR BOR LXOR BXOR`
`MAXLOC MINLOC`

### Groups
- `MPI_Comm_group(comm, *group)`: Get group of given comm
- `MPI_Group_excl(group, n, *ranks, *new)`: Make new group with processes
  in `ranks` excluded
- `MPI_Group_free(group)`: Free a group
- `MPI_Comm_create(comm, group, *new)`: Create a new comm. Given comm must be
  a superset of the group.
- `MPI_Comm_free(comm)`: Free a comm

### MUST
Analyzer for MPI programs to determine correctness, can detect deadlocks,
leaks, mismatching data types.

Includes LLVM extensions TypeART for typechecking; both during compilation
and at runtime, to catch errors arising from C's terrible type system
and the way MPI deals with it.

### Threading
- MPI processes can have multiple threads; MPI is thread-safe
- Threads are not separate
- `MPI_Init_thread(argc, argv, required, *provided)` must be used for init
- Various levels of support by impl; programmer must confirm that the required
  level was provided


## Collective operations
- Common patterns already provided
- Often more efficient to due optimized algorithm and exploitation of target
  platform features
- Barriers as usual, `MPI_Barrier(comm)`
- Gather gets buffer from all processes into the root
- Scatter is inverse to gather
- 

### Classification
- All-to-all: All processes contribute to and receive the result
    - Allgather, Alltoall, Allreduce, Barrier
- All-to-one: All processes contribute, one receives the result
    - Gather, Reduce
- One-to-all: All processes receive the result
    - Bcast, Scatter
- Others
    - Scan, Exscan
